%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[a4paper,11pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
\edef\sphinxdqmaybe{\ifdefined\DeclareUnicodeCharacterAsOptional\string"\fi}
  \DeclareUnicodeCharacter{\sphinxdqmaybe00A0}{\nobreakspace}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2500}{\sphinxunichar{2500}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2502}{\sphinxunichar{2502}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2514}{\sphinxunichar{2514}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe251C}{\sphinxunichar{251C}}
  \DeclareUnicodeCharacter{\sphinxdqmaybe2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}

% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\figurename}{Fig.}}
\addto\captionsenglish{\renewcommand{\tablename}{Table}}
\addto\captionsenglish{\renewcommand{\literalblockname}{Listing}}

\addto\captionsenglish{\renewcommand{\literalblockcontinuedname}{continued from previous page}}
\addto\captionsenglish{\renewcommand{\literalblockcontinuesname}{continues on next page}}
\addto\captionsenglish{\renewcommand{\sphinxnonalphabeticalgroupname}{Non-alphabetical}}
\addto\captionsenglish{\renewcommand{\sphinxsymbolsname}{Symbols}}
\addto\captionsenglish{\renewcommand{\sphinxnumbersname}{Numbers}}

\addto\extrasenglish{\def\pageautorefname{page}}

\setcounter{tocdepth}{0}



\title{Documentation of the Skills and Wages project}
\date{02 March 2019}
\release{}
\author{Poooja Bansal}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\maketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}



\chapter{Introduction}
\label{\detokenize{introduction:introduction}}\label{\detokenize{introduction:id1}}\label{\detokenize{introduction::doc}}
Documentation on the rationale, Waf, and more background is at \sphinxurl{http://hmgaudecker.github.io/econ-project-templates/}

The Python version of the template uses a modified version of Stachurski’s and Sargent’s code accompanying their Online Course \sphinxcite{references:stachurskisargent13} for Schelling’s (1969, \sphinxcite{references:schelling69}) segregation model as the running exmaple.


\section{Getting started}
\label{\detokenize{introduction:getting-started}}\label{\detokenize{introduction:id4}}
\sphinxstylestrong{This assumes you have completed the steps in the} \sphinxhref{https://github.com/hmgaudecker/econ-project-templates/}{README.md file} \sphinxstylestrong{and everything worked.}

The logic of the project template works by step of the analysis:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
Data management

\item {} 
The actual estimations / simulations / ?

\item {} 
Visualisation and results formatting (e.g. exporting of LaTeX tables)

\item {} 
Research paper and presentations.

\end{enumerate}

It can be useful to have code and model parameters available to more than one of these steps, in that case see sections \DUrole{xref,std,std-ref}{model\_specifications}, \DUrole{xref,std,std-ref}{model\_code}, and {\hyperref[\detokenize{library:library}]{\sphinxcrossref{\DUrole{std,std-ref}{Code library}}}}.

First of all, think about whether this structure fits your needs \textendash{} if it does not, you need to adjust (delete/add/rename) directories and files in the following locations:
\begin{itemize}
\item {} 
Directories in \sphinxstylestrong{src/};

\item {} 
The list of included wscript files in \sphinxstylestrong{src/wscript};

\item {} 
The documentation source files in \sphinxstylestrong{src/documentation/} (Note: These should follow the directories in \sphinxstylestrong{src} exactly);

\item {} 
The list of included documentation source files in \sphinxstylestrong{src/documentation/index.rst}

\end{itemize}

Later adjustments should be painlessly possible, so things won’t be set in stone.

Once you have done that, move your source data to \sphinxstylestrong{src/original\_data/} and start filling up the actual steps of the project workflow (data management, analysis, final steps, paper). All you should need to worry about is to call the correct task generators in the wscript files. Always specify the actions in the wscript that lives in the same directory as your main source file. Make sure you understand how the paths work in Waf and how to use the auto-generated files in the language you are using particular language (see the section {\hyperref[\detokenize{introduction:project-paths}]{\sphinxcrossref{\DUrole{std,std-ref}{Project paths}}}} below).


\section{Project paths}
\label{\detokenize{introduction:project-paths}}\label{\detokenize{introduction:id5}}
A variety of project paths are defined in the top-level wscript file. These are exported to header files in other languages. So in case you require different paths (e.g. if you have many different datasets, you may want to have one path to each of them), adjust them in the top-level wscript file.

The following is taken from the top-level wscript file. Modify any project-wide path settings there.

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]


\PYG{k}{def} \PYG{n+nf}{set\PYGZus{}project\PYGZus{}paths}\PYG{p}{(}\PYG{n}{ctx}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Return a dictionary with project paths represented by Waf nodes.\PYGZdq{}\PYGZdq{}\PYGZdq{}}

    \PYG{n}{pp} \PYG{o}{=} \PYG{n}{OrderedDict}\PYG{p}{(}\PYG{p}{)}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{PROJECT\PYGZus{}ROOT}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{.}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{IN\PYGZus{}DATA}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{src/original\PYGZus{}data/}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{LIBRARY}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{src/library}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{BLD}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OUT\PYGZus{}DATA}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}out\PYGZcb{}}\PYG{l+s+s2}{/out/data}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OUT\PYGZus{}ANALYSIS}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}out\PYGZcb{}}\PYG{l+s+s2}{/out/analysis}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OUT\PYGZus{}FINAL}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}out\PYGZcb{}}\PYG{l+s+s2}{/out/final}\PYG{l+s+s2}{\PYGZdq{}}
    \PYG{n}{pp}\PYG{p}{[}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{OUT\PYGZus{}FIGURES}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{]} \PYG{o}{=} \PYG{n}{f}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+si}{\PYGZob{}out\PYGZcb{}}\PYG{l+s+s2}{/out/figures}\PYG{l+s+s2}{\PYGZdq{}}
   



\end{sphinxVerbatim}

As should be evident from the similarity of the names, the paths follow the steps of the analysis in the \sphinxcode{\sphinxupquote{src}} directory:
\begin{enumerate}
\def\theenumi{\arabic{enumi}}
\def\labelenumi{\theenumi .}
\makeatletter\def\p@enumii{\p@enumi \theenumi .}\makeatother
\item {} 
\sphinxstylestrong{data\_management} \(\rightarrow\) \sphinxstylestrong{OUT\_DATA}

\item {} 
\sphinxstylestrong{analysis} \(\rightarrow\) \sphinxstylestrong{OUT\_ANALYSIS}

\item {} 
\sphinxstylestrong{final} \(\rightarrow\) \sphinxstylestrong{OUT\_FINAL}, \sphinxstylestrong{OUT\_FIGURES}, \sphinxstylestrong{OUT\_TABLES}

\end{enumerate}

These will re-appear in automatically generated header files by calling the \sphinxcode{\sphinxupquote{write\_project\_paths}} task generator (just use an output file with the correct extension for the language you need \textendash{} \sphinxcode{\sphinxupquote{.py}}, \sphinxcode{\sphinxupquote{.r}}, \sphinxcode{\sphinxupquote{.m}}, \sphinxcode{\sphinxupquote{.do}})

By default, these header files are generated in the top-level build directory, i.e. \sphinxcode{\sphinxupquote{bld}}. The Python version defines a dictionary \sphinxcode{\sphinxupquote{project\_paths}} and a couple of convencience functions documented below. You can access these by adding a line:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{bld}\PYG{n+nn}{.}\PYG{n+nn}{project\PYGZus{}paths} \PYG{k}{import} \PYG{n}{XXX}
\end{sphinxVerbatim}

at the top of you Python-scripts. Here is the documentation of the module:
\begin{quote}

\sphinxstylestrong{bld.project\_paths}

\phantomsection\label{\detokenize{introduction:module-bld.project_paths}}\index{bld.project\_paths (module)@\spxentry{bld.project\_paths}\spxextra{module}}
Define a dictionary \sphinxstyleemphasis{project\_paths} with path
definitions for the entire project.

This module is automatically generated by Waf, never change it!

If paths need adjustment, change them in the root wscript file.
\index{project\_paths\_join() (in module bld.project\_paths)@\spxentry{project\_paths\_join()}\spxextra{in module bld.project\_paths}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{introduction:bld.project_paths.project_paths_join}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_paths\_join}}}{\emph{key}, \emph{*args}}{}
Given input of a \sphinxstyleemphasis{key} in the \sphinxstyleemphasis{project\_paths} dictionary and a number
of path arguments \sphinxstyleemphasis{args}, return the joined path constructed by:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{project\PYGZus{}paths}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{p}{,} \PYG{o}{*}\PYG{n}{args}\PYG{p}{)}
\end{sphinxVerbatim}

\end{fulllineitems}

\index{project\_paths\_join\_latex() (in module bld.project\_paths)@\spxentry{project\_paths\_join\_latex()}\spxextra{in module bld.project\_paths}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{introduction:bld.project_paths.project_paths_join_latex}}\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{project\_paths\_join\_latex}}}{\emph{key}, \emph{*args}}{}
Given input of a \sphinxstyleemphasis{key} in the \sphinxstyleemphasis{project\_paths} dictionary and a number
of path arguments \sphinxstyleemphasis{args}, return the joined path constructed by:

\fvset{hllines={, ,}}%
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{os}\PYG{o}{.}\PYG{n}{path}\PYG{o}{.}\PYG{n}{join}\PYG{p}{(}\PYG{n}{project\PYGZus{}paths}\PYG{p}{[}\PYG{n}{key}\PYG{p}{]}\PYG{p}{,} \PYG{o}{*}\PYG{n}{args}\PYG{p}{)}
\end{sphinxVerbatim}

and backslashes replaced by forward slashes.

\end{fulllineitems}

\end{quote}


\chapter{Original data}
\label{\detokenize{original_data:original-data}}\label{\detokenize{original_data:id1}}\label{\detokenize{original_data::doc}}
Documentation of the different datasets in \sphinxstyleemphasis{original\_data}.

In the original data section you would store the raw data, which you should not manipulate to ensure reproducibility.

If you want to include multiple data sets, you can also create subfolders for the sake of a clear structure.


\chapter{Data management}
\label{\detokenize{data_management:data-management}}\label{\detokenize{data_management:id1}}\label{\detokenize{data_management::doc}}
Documentation of the code in \sphinxstyleemphasis{src.data\_management}.

\phantomsection\label{\detokenize{data_management:module-src.data_management.get_skill_data}}\index{src.data\_management.get\_skill\_data (module)@\spxentry{src.data\_management.get\_skill\_data}\spxextra{module}}
We start with merging all the relevant data files. SOEP has provided with the data for two different waves using different questionnaires. We first merge all of the datasets and then keep only the useful variables.
Now, all our data for skill variables, be it cognitive or non-cognitive was categorical. So we first converted the categorical figures into numeric to perform mathematical operations on them. We then rename the important variables to be used later for our convenience.
Then we restrict our data with individuals of age between 20 and 60 and drop individuals with occupations not useful in our analysis. After this, we dropped all the missing values by first replacing them nan.
The variables for Cognitive abilities were standardised using the sklearn library.
For personality we had 15 variables to be reduced to 5 be taking averages of 3 variables corresponding to a particular personality trait. Out of those 15, 4 had to be reversed since they represented the opposite quality corresponding the respective trait. We then created 5 variables by taking the average and standardising them.
We then generated the experience and experience squared variables for the Mincer equation.
We then took a log of wages to improve our regression model.
For occupations, we combined similar categories and sorted them in order.


\chapter{Main model estimations / simulations}
\label{\detokenize{analysis:main-model-estimations-simulations}}\label{\detokenize{analysis:analysis}}\label{\detokenize{analysis::doc}}
Documentation of the code in \sphinxstyleemphasis{src.analysis}. This is the core of the project.


\section{Regression}
\label{\detokenize{analysis:module-src.analysis.reg_tree}}\label{\detokenize{analysis:regression}}\index{src.analysis.reg\_tree (module)@\spxentry{src.analysis.reg\_tree}\spxextra{module}}
We run the regression using statsmodel python package.
\begin{description}
\item[{First we investigate the returns to earnings by  using the basic Mincer Equation which used 3 variables}] \leavevmode{[}Years of education, Years of Experience and Square of years of experience.{]}
We will then expand the basic specification by adding the cognitive skills : Fluency and Symbol test score which we standardised.
We then introduce only non cognitive skills in the basic specification : Openness, Conscientiousness, Extraversion , Agreeableness and Neuroticism.

\end{description}

We then add both skills (Cognitive and Non-Cognitive)to the specification.

We define our independent variables as X and dependent variables as Y, For each specification, we generate a new matrix. We fit our linear model using the OLS module offered by the sm library and then print the summary which contains the regression output for all the defined model.

After the first 4 regression, we perform regression for different occupational groups by defining a loop for the values in the our column occupation which contains : 1,2,3,4 thus generates results for 4 different outputs for all categories.


\section{Decision Tree}
\label{\detokenize{analysis:decision-tree}}

\chapter{Visualisation and results formatting}
\label{\detokenize{final:visualisation-and-results-formatting}}\label{\detokenize{final:final}}\label{\detokenize{final::doc}}
Documentation of the code in \sphinxstyleemphasis{src.final}.


\section{Schelling example}
\label{\detokenize{final:schelling-example}}

\chapter{Research paper / presentations}
\label{\detokenize{paper:research-paper-presentations}}\label{\detokenize{paper:paper}}\label{\detokenize{paper::doc}}
Purpose of the different files (rename them to your liking):
\begin{itemize}
\item {} 
\sphinxcode{\sphinxupquote{research\_paper.tex}} contains the actual paper.

\item {} 
\sphinxcode{\sphinxupquote{research\_pres\_30min.tex}} contains a typical conference presentation.

\item {} 
\sphinxcode{\sphinxupquote{research\_pres\_90min.tex}} contains a full-length seminar presentation (add by yourself).

\item {} 
\sphinxcode{\sphinxupquote{formulas}} contains short files with the LaTeX formulas \textendash{} put these into a library for re-use in paper and presentations.

\end{itemize}


\chapter{Code library}
\label{\detokenize{library:code-library}}\label{\detokenize{library:library}}\label{\detokenize{library::doc}}
The directory \sphinxstyleemphasis{src.library} provides code that may be used by different steps of the analysis. Little code snippets for input / output or stuff that is not directly related to the model would go here.

The distinction from the \DUrole{xref,std,std-ref}{model\_code} directory is a bit arbitrary, but I have found it useful in the past.


\chapter{References}
\label{\detokenize{references:references}}\label{\detokenize{references:id1}}\label{\detokenize{references::doc}}


\begin{sphinxthebibliography}{1}
\bibitem[1]{references:schelling69}
Thomas C. Schelling. Models of segregation. \sphinxstyleemphasis{The American Economic Review}, 59(2):488\textendash{}493, 1969.
\bibitem[2]{references:stachurskisargent13}
John Stachurski and Thomas J. Sargent. Quantitative economics. Available at http://quant-econ.net/index.html, 2013.
\end{sphinxthebibliography}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{a}
\item\relax\sphinxstyleindexentry{src.analysis.reg\_tree}\sphinxstyleindexpageref{analysis:\detokenize{module-src.analysis.reg_tree}}
\indexspace
\bigletter{b}
\item\relax\sphinxstyleindexentry{bld.project\_paths}\sphinxstyleindexpageref{introduction:\detokenize{module-bld.project_paths}}
\indexspace
\bigletter{d}
\item\relax\sphinxstyleindexentry{src.data\_management.get\_skill\_data}\sphinxstyleindexpageref{data_management:\detokenize{module-src.data_management.get_skill_data}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}